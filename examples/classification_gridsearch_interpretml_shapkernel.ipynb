{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/TorkamaniLab/lohrasb.git\n",
      "  Cloning https://github.com/TorkamaniLab/lohrasb.git to /private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-req-build-jjlgzu2z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TorkamaniLab/lohrasb.git /private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-req-build-jjlgzu2z\n",
      "  Resolved https://github.com/TorkamaniLab/lohrasb.git to commit 47dbe32bd88d5a1d5f318324c89a1c4d58cbf526\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[17 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/hjavedani/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/hjavedani/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/hjavedani/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-build-env-yvaxnri4/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 341, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-build-env-yvaxnri4/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 323, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-build-env-yvaxnri4/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 488, in run_setup\n",
      "  \u001b[31m   \u001b[0m     self).run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-build-env-yvaxnri4/overlay/lib/python3.7/site-packages/setuptools/build_meta.py\", line 338, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'requirements_prod.txt'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/TorkamaniLab/lohrasb.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/ipykernel_33892/2286533747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlohrasb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from feature_engine.imputation import (\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from lohrasb.best_estimator import BaseModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import (\n",
    "    CategoricalImputer,\n",
    "    MeanMedianImputer\n",
    "    )\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score)\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from interpret import show\n",
    "from interpret.blackbox import ShapKernel\n",
    "import shap\n",
    "\n",
    "\n",
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "set_visualize_provider(InlineProvider())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Use Adult Data Set (a classification problem)\n",
    "  \n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata= \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "# column names\n",
    "col_names=[\"age\", \"workclass\", \"fnlwgt\" , \"education\" ,\"education-num\",\n",
    "\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\n",
    "\"native-country\",\"label\"\n",
    "]\n",
    "# read data\n",
    "data = pd.read_csv(urldata,header=None,names=col_names,sep=',')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['label']=='<=50K','label']=0\n",
    "data.loc[data['label']==' <=50K','label']=0\n",
    "\n",
    "data.loc[data['label']=='>50K','label']=1\n",
    "data.loc[data['label']==' >50K','label']=1\n",
    "\n",
    "data['label']=data['label'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != \"label\"]\n",
    "y = data.loc[:, data.columns == \"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, \\\n",
    "     test_size=0.33, stratify=y['label'], random_state=42)\n",
    "\n",
    "y_train=y_train.values.ravel()\n",
    "y_test=y_test.values.ravel()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find feature types for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols =  X_train.select_dtypes(include=['int']).columns.tolist()\n",
    "float_cols =  X_train.select_dtypes(include=['float']).columns.tolist()\n",
    "cat_cols =  X_train.select_dtypes(include=['object']).columns.tolist()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define estimator and set its arguments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "estimator_params = {\n",
    "        \"max_depth\": [4, 5],\n",
    "        \"n_estimators\":[100,200],\n",
    "        \"max_features\" :[\"sqrt\", \"log2\"],\n",
    "\n",
    "\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {  # params for fit method or fit_params \n",
    "            'fit_grid_kwargs' :{\n",
    "            'sample_weight':None,\n",
    "            },\n",
    "            # params for GridSearchCV \n",
    "            'grid_search_kwargs' : {\n",
    "            'estimator':estimator,\n",
    "            'param_grid':estimator_params,\n",
    "            'scoring' :'f1',\n",
    "            'verbose':3,\n",
    "            'n_jobs':-1,\n",
    "            'cv':KFold(2),\n",
    "            }\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox_model = BaseModel().optimize_by_gridsearchcv(\n",
    "    kwargs=kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline =Pipeline([\n",
    "            # int missing values imputers\n",
    "            ('intimputer', MeanMedianImputer(\n",
    "                imputation_method='median', variables=int_cols)),\n",
    "            # category missing values imputers\n",
    "            ('catimputer', CategoricalImputer(variables=cat_cols)),\n",
    "            #\n",
    "            ('catencoder', OrdinalEncoder()),\n",
    "            # classification model\n",
    "            #('obj', RandomForestClassifier())\n",
    "\n",
    " ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.fit_transform(X_train,y_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "y_pred = blackbox_model.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check performance of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score : ')\n",
    "print(f1_score(y_test,y_pred))\n",
    "print('Classification report : ')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Interpret of the pipeline and its decisions with SHAP. The visualizations provided will be for local explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set is big only we use 500 as a sample\n",
    "shap_kernel = ShapKernel(predict_fn=blackbox_model.predict_proba, data=shap.sample(X_train,500))\n",
    "shap_local = shap_kernel.explain_local(X_test[:20], y_test[:20])\n",
    "show(shap_local)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ced68e88e9060e5bcf2eaa5b2d4f8fc97e4d610a52d347137abf879072ffb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
