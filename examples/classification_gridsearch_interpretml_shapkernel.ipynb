{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/ipykernel_33892/2286533747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlohrasb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from feature_engine.imputation import (\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from lohrasb.best_estimator import BaseModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import (\n",
    "    CategoricalImputer,\n",
    "    MeanMedianImputer\n",
    "    )\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score)\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from interpret import show\n",
    "from interpret.blackbox import ShapKernel\n",
    "import shap\n",
    "\n",
    "\n",
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "set_visualize_provider(InlineProvider())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Use Adult Data Set (a classification problem)\n",
    "  \n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata= \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "# column names\n",
    "col_names=[\"age\", \"workclass\", \"fnlwgt\" , \"education\" ,\"education-num\",\n",
    "\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\n",
    "\"native-country\",\"label\"\n",
    "]\n",
    "# read data\n",
    "data = pd.read_csv(urldata,header=None,names=col_names,sep=',')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['label']=='<=50K','label']=0\n",
    "data.loc[data['label']==' <=50K','label']=0\n",
    "\n",
    "data.loc[data['label']=='>50K','label']=1\n",
    "data.loc[data['label']==' >50K','label']=1\n",
    "\n",
    "data['label']=data['label'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != \"label\"]\n",
    "y = data.loc[:, data.columns == \"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, \\\n",
    "     test_size=0.33, stratify=y['label'], random_state=42)\n",
    "\n",
    "y_train=y_train.values.ravel()\n",
    "y_test=y_test.values.ravel()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find feature types for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols =  X_train.select_dtypes(include=['int']).columns.tolist()\n",
    "float_cols =  X_train.select_dtypes(include=['float']).columns.tolist()\n",
    "cat_cols =  X_train.select_dtypes(include=['object']).columns.tolist()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define estimator and set its arguments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "estimator_params = {\n",
    "        \"max_depth\": [4, 5],\n",
    "        \"n_estimators\":[100,200],\n",
    "        \"max_features\" :[\"sqrt\", \"log2\"],\n",
    "\n",
    "\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {  # params for fit method or fit_params \n",
    "            'fit_grid_kwargs' :{\n",
    "            'sample_weight':None,\n",
    "            },\n",
    "            # params for GridSearchCV \n",
    "            'grid_search_kwargs' : {\n",
    "            'estimator':estimator,\n",
    "            'param_grid':estimator_params,\n",
    "            'scoring' :'f1',\n",
    "            'verbose':3,\n",
    "            'n_jobs':-1,\n",
    "            'cv':KFold(2),\n",
    "            }\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox_model = BaseModel().optimize_by_gridsearchcv(\n",
    "    kwargs=kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline =Pipeline([\n",
    "            # int missing values imputers\n",
    "            ('intimputer', MeanMedianImputer(\n",
    "                imputation_method='median', variables=int_cols)),\n",
    "            # category missing values imputers\n",
    "            ('catimputer', CategoricalImputer(variables=cat_cols)),\n",
    "            #\n",
    "            ('catencoder', OrdinalEncoder()),\n",
    "            # classification model\n",
    "            #('obj', RandomForestClassifier())\n",
    "\n",
    " ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.fit_transform(X_train,y_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "y_pred = blackbox_model.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check performance of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score : ')\n",
    "print(f1_score(y_test,y_pred))\n",
    "print('Classification report : ')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Interpret of the pipeline and its decisions with SHAP. The visualizations provided will be for local explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set is big only we use 500 as a sample\n",
    "shap_kernel = ShapKernel(predict_fn=blackbox_model.predict_proba, data=shap.sample(X_train,500))\n",
    "shap_local = shap_kernel.explain_local(X_test[:20], y_test[:20])\n",
    "show(shap_local)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ced68e88e9060e5bcf2eaa5b2d4f8fc97e4d610a52d347137abf879072ffb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
